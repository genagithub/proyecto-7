{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿como se comportan los valores de las residencias en California?\n",
    "Conocido por su diversidad geográfica y económica, su mercado inmobiliario es influenciado por una variedad de factores. Los compradores y vendedores necesitan de una visualización geográfica que describa las ubicaciones y características inmobiliarias de las residencias para una mejor perspectiva. Además, si se estaría considerando inversiones futuras y se desea evaluar la rentabilidad de un hogar, una estimación de precios de venta óptima puede llegar a traer ideas claras y decisiones convincentes."
   ]
},
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "\n",
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "df[\"MedHouseVal\"] = data[\"target\"]\n",
    "df[\"MedHouseVal\"] = df[\"MedHouseVal\"] * 100000\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "En el proyecto 4(evaluación en riesgo de crédito) habiamos mencionado y llevado a cabo la técnica de Bagging, donde generábamos distintos metaestimadores entrenados de forma independiente y se tomaban en cuenta los resultados de cada uno. En este caso, cada metaestimador capacitará y solucionará los errores del siguiente potenciando cada vez más la precisión final, es decir que su escalabilidad es vertical en lugar de horizontal. Requieren de una hiperparametrización compleja y una tendencia, si no realiza correctamente lo anterior mencionado, al sobreajuste, es decir, modelos con una precisión alta sobre un grupos de datos en particular pero con la poca adaptación para resolver nuevas situaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[df.columns[:-1]],\n",
    "                                                    df[\"MedHouseVal\"],\n",
    "                                                    test_size=0.25)\n",
    "\n",
    "turned_parameters = {\n",
    "    \"n_estimators\":[100,200,300,400,500],\n",
    "    \"subsample\":[0.7,0.75,0.8,0.85,0.9],\n",
    "    \"max_depth\":[3,4,5,6,7],\n",
    "    \"learning_rate\":[0.2,0.3,0.4,0.5,0.55],\n",
    "    \"min_child_weight\":[2,3,4,5,6],\n",
    "    \"gamma\":[0,1,2,3,4]\n",
    "}\n",
    "\n",
    "xgbr_test = XGBRegressor()\n",
    "\n",
    "# implementando Random Search CV para obtener los mejores valores de hiperparámetros\n",
    "random_search = RandomizedSearchCV(xgbr_test, turned_parameters,cv=5)\n",
    "random_search.fit(df[df.columns[:-1]], df[\"MedHouseVal\"])\n",
    "\n",
    "# asignación de los valores óptimos obtenidos por el algoritmo\n",
    "xgbr = XGBRegressor(n_estimators = random_search.best_params_[\"n_estimators\"],\n",
    "                    subsample = random_search.best_params_[\"subsample\"],\n",
    "                    max_depth = random_search.best_params_[\"max_depth\"],\n",
    "                    learning_rate = random_search.best_params_[\"learning_rate\"],\n",
    "                    min_child_weight = random_search.best_params_[\"min_child_weight\"],\n",
    "                    gamma = random_search.best_params_[\"gamma\"])\n",
    "\n",
    "xgbr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compensación bías - varianza\n",
    "Conforme hemos avanzados en los problemas, definimos los principales desafíos que se interponen en la precisión y eficacia de un modelo predictivo, la realidad es que nunca se puede estar libre de errores y la mejor solución es comprender las diferentes fuentes de error nos ayudará a obtener mejores resultados. El objetivo es lograr un bías bajo y una varianza baja, a su vez, el algoritmo debe lograr un buen rendimiento de predicción, el bías frente a la varianza se refiere a la precisión frente a la consistencia, es decir, aumentar la varianza disminuye la inprecisión en promedio pero aumenta la inconsistencia mientras que aumentar el bías disminuye la inconsistencia pero aumenta la inprecisión en promedio. El punto ideal para cualquier modelo es el nivel de complejidad en donde el aumento del bías es equivalente a la reducción de la varianza, por lo tanto se requiere enconctrar un buen equilibrio entre ambos errores de manera que minimice el error total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = xgbr.predict(x_test)\n",
    "\n",
    "# Raíz cuadrada del error cuadrático medio(RMSE)\n",
    "# similar a la desviación éstandar, muestran la variabiliad de los residuos en la misma unidad que los valores reales\n",
    "\n",
    "metrics = f\"RMSE: {round(root_mean_squared_error(predicts,y_test))}\"\n",
    "scatter = go.Figure()\n",
    "scatter.add_trace(go.Scatter(x=y_test, y=predicts, mode=\"markers\", marker_color=\"rgba(255,0,0,0.45)\"))\n",
    "scatter.update_xaxes(title_text=\"Valores reales\")\n",
    "scatter.update_yaxes(title_text=\"Predicciones\")\n",
    "scatter.update_layout(title=metrics)\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje no supervisado\n",
    "las observaciones no tienen una respuesta asociada que guíe el aprendizaje, uno de sus algoritmos es Kmeans que, mediante un proceso iterativo, genera sus propias etiquetas determinando grupos de datos asociables en función de sus acercamientos estadísticos. El modelo de clustering requiere de un hiperparámetro que es la número de centroides o K-means, estos funcionan como valores dispersados entre los datos cuya cercanía irá asociandolos conformando los clústers, iterativamente los centroides seguirán desplazándose por la región reasignando nuevos valores hasta lograr alcanzar la homogeneidad. El método del codo se utiliza a la hora de designar este valor numérico y dónde el la idea es visualizar en un gráfico cartesiano diferentes cantidades de centroides e inercias(distancia entre los miembros de los clústers y su centroide) y distinguir el punto medio de ambos. También existen métricas especializadas en evaluar esta clase de modelos siendo estas Coeficiente de Silueta e Índice Davies-Bouldin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "inertias = []\n",
    "\n",
    "for c in range(3,12):\n",
    "    kmeans = KMeans(n_clusters=c).fit(df[\"MedHouseVal\"].values.reshape((-1,1)))\n",
    "    clusters.append(c)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "kmeans = KMeans(n_clusters=5).fit(df[\"MedHouseVal\"].values.reshape((-1,1)))\n",
    "inertia = kmeans.inertia_\n",
    "\n",
    "plt.plot(clusters, inertias, marker=\"o\")\n",
    "plt.text(int(str(kmeans)[-2])+0.1, inertia, \"Valor del codo\")\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5).fit(df[\"MedHouseVal\"].values.reshape((-1,1)))\n",
    "\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "df[\"clusters\"] = clusters\n",
    "\n",
    "range_values = np.array([])\n",
    "\n",
    "for c in df[\"clusters\"].sort_values().unique():\n",
    "    cluster = df.loc[df[\"clusters\"] == c,[\"clusters\",\"MedHouseVal\"]]\n",
    "    max_value = str(cluster[\"MedHouseVal\"].max())\n",
    "    min_value = str(cluster[\"MedHouseVal\"].min())\n",
    "    range_values = np.append(range_values,min_value)\n",
    "    range_values = np.append(range_values,max_value)\n",
    "    \n",
    "range_values = range_values.reshape((-1,2))\n",
    "    \n",
    "df[\"clusters\"] = df[\"clusters\"].replace(\n",
    "    {\n",
    "        0:f\"0 ({range_values[0,0][:8]}$-{range_values[0,1][:8]}$)\",\n",
    "        1:f\"1 ({range_values[1,0][:8]}$-{range_values[1,1][:8]}$)\",\n",
    "        2:f\"2 ({range_values[2,0][:8]}$-{range_values[2,1][:8]}$)\",\n",
    "        3:f\"3 ({range_values[3,0][:8]}$-{range_values[3,1][:8]}$)\",\n",
    "        4:f\"4 ({range_values[4,0][:8]}$-{range_values[4,1][:8]}$)\"\n",
    "    })\n",
    "\n",
    "clusters_count = df[\"clusters\"].value_counts().reset_index()\n",
    "\n",
    "cluster_map = make_subplots(rows=2, cols=1, subplot_titles=[\"Rangos de precios\",\"Conteo de rangos\"])\n",
    "\n",
    "def make_figure(df, cluster):\n",
    "\n",
    "    var_x = df.loc[df[\"clusters\"] == cluster,[\"Longitude\", \"clusters\"]]\n",
    "    var_y = df.loc[df[\"clusters\"] == cluster,[\"Latitude\", \"clusters\"]]\n",
    "\n",
    "    cluster_map.add_trace(go.Scatter( \n",
    "        x=var_x[\"Longitude\"], \n", 
    "        y=var_y[\"Latitude\"], \n",
    "        mode=\"markers\", \n",
    "        marker=dict( \n",
    "        size=9, \n",
    "        symbol=\"circle\", \n",
    "        line=dict(width=0.5, color=\"white\") \n",
    "        ), \n",
    "        name=cluster), row=1, col=1) \n",
    "\n",
    "make_figure(df, df[\"clusters\"].unique()[0])\n",
    "make_figure(df, df[\"clusters\"].unique()[1])\n",
    "make_figure(df, df[\"clusters\"].unique()[2])\n",
    "make_figure(df, df[\"clusters\"].unique()[3])\n",
    "make_figure(df, df[\"clusters\"].unique()[4])\n",
    "\n",
    "cluster_map.update_xaxes(row=1, col=1, range=[-125,-114], constrain=\"domain\")\n",
    "cluster_map.update_yaxes(row=1, col=1, range=[32,42], constrain=\"domain\", scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "clusters_count = df[\"clusters\"].value_counts().reset_index()\n",
    "\n",
    "cluster_map.add_trace(go.Bar(x=clusters_count[\"clusters\"], y=clusters_count[\"count\"]), row=2, col=1)\n",
    "\n",
    "cluster_map.update_layout(height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard que funciona como mapa geográfico descriptivo de las viviendas y muestra sus rangos de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(id=\"body\",className=\"e5_body\",children=[\n",
    "        html.H1(\"Inmuebles en California \",id=\"title\",className=\"e5_title\"),\n",
    "            dcc.Dropdown(id=\"dropdown\",className=\"e5_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Valor de precio\",\"value\":\"MedHouseVal\"},\n",
    "                            {\"label\":\"Ingreso medio\",\"value\":\"MedInc\"},\n",
    "                            {\"label\":\"Edad media\",\"value\":\"HouseAge\"},\n",
    "                            {\"label\":\"Promedio de habitaciones\",\"value\":\"AveRooms\"},\n",
    "                            {\"label\":\"Promedio de dormitorios\",\"value\":\"AveBedrms\"},\n",
    "                            {\"label\":\"Población\",\"value\":\"Population\"},\n",
    "                            {\"label\":\"Promedio de ocupación\",\"value\":\"AveOccuption\"}\n",
    "                        ],\n",
    "                        value=\"MedHouseVal\",\n",
    "                        multi=False,\n",
    "                        clearable=False),\n",
    "        dcc.Graph(id=\"graph_1\",className=\"e5_graph\",figure={}),\n",
    "        dcc.Graph(id=\"graph_2\",className=\"e5_graph\",figure=cluster_map)\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id=\"graph_1\",component_property=\"figure\"),\n",
    "    [Input(component_id=\"dropdown\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "def update_graph(slct_var):\n",
    "    \n",
    "    california_map = go.Figure(go.Scattermapbox(\n",
    "        lat=df[\"Latitude\"],\n",
    "        lon=df[\"Longitude\"],\n",
    "        mode=\"markers\",\n",
    "        marker=go.scattermapbox.Marker(\n",
    "            size=9,\n",
    "            color=df[slct_var],\n",
    "            cmin=df[slct_var].min(),\n",
    "            cmax=df[slct_var].max(),\n",
    "            showscale=True\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    california_map.update_layout(\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    mapbox_zoom=4.8,\n",
    "    mapbox_center_lat = 37.0,\n",
    "    mapbox_center_lon = -119.0,\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n",
    "    )\n",
    "    \n",
    "    return california_map\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
